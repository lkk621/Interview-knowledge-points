1绪论
1.1研究背景及意义
随着我国基础设施建设的逐步完善，人民生活质量和水平逐步提升，这对城市信息化提出了更高的要求。加之近些年来“平安城市”、“智慧城市”等词逐渐出现在政府工作报告中，“平安城市”、“智慧城市”的概念越来越深入人心。而随着科学技术的不断发展，视频监控系统在我国各个地方逐步普及，尤其在交通路口、机场，火车站、商场、公园等人员复杂的公共场所。通过安装监控摄像头，可以第一时间获取各种突发事件的信息，以便于及时处理。例如走失人员搜索，犯罪嫌疑人追踪等。而传统的做法是工作人员坐在电脑面前对摄像头拍到的图片进行一帧一帧的查看，如果事件发生在一个有上百个摄像头的大型公共场所，这么做显然要耗费大量人力，并且人在长时间观察监控视频时，很难一直保持注意力高度集中，更不可能一天24小时都在工作。而随着各种互联网+应用的发展，智慧安防也逐步发展起来。智慧安防通过把传统摄像头、互联网及当前火热的人工智能技术结合起来，在面对各种复杂的场景时，显示了其强大的信息处理能力，为平安城市、智慧城市的建设提供了更好的解决方案。
随着数字图像处理、大数据、人工智能等技术的快速发展及其在安防领域的应用，智慧安防技术也得到了快速发展。与传统安防技术相比，智慧安防技术能对海量数据进行更高效的处理和更精确的分析，从而在各种复杂的场景下更好的协助工作人员。而行人重识别技术则是一个智慧安防系统里面最核心的技术之一，其任务是在给定的大量图像数据里面自动搜索出某个人物的其他图像，并且这些图像都是由不同摄像头以不同视角拍到的。该项技术除了应用在安防领域外，还可以应用到了商业领域。比如在某个超市里面，可以根据摄像头拍到的图像，自动分析出一个顾客进店之后在哪些商品前逗留了多长时间，据此分析出顾客对哪些商品感兴趣，以辅助商业决策。
学术界又把行人重识别称为行人再识别（Person Re-identification），简称ReID。作为图像检索的一个子问题，可以应用到无法进行人脸识别的一些场景。例如现在的监控摄像头大都使用广角镜头，以追求拍摄到更大的范围，这会导致单位监控区域的像素变少，拍摄到的人脸模糊，不足以进行人脸识别；而且有时还会因为拍摄角度的原因，导致只能拍到头顶、侧脸或者背面；还有的情况下要追踪的目标戴有口罩、面具等也无法进行人脸识别。在这些场景下，行人重识别技术可以作为作为人脸识别技术的一个扩充，以实现目标跟踪在时间上和空间上的连续性。
来自不同拍摄设备的同一个人的图像会因为角度的不同导致图像中行人姿态不一样，或者距离远导致分辨率低，又或者人物的某部分被遮挡了，这些都会给行人重识别带来不同程度的挑战，如图1所示。其中遮挡问题带来的挑战尤为严重，这是因为：（1）遮挡导致行人特征减少。目前的行人重识别任务都是靠提取有鉴别力的特征来进行行人识别的，算法的准确性在很大程度上取决于提取到的特征是否具有足够的鉴别力。（2）不同行人可能被相似的遮挡物遮挡，在进行行人重识别任务时遮挡会引入错误的信息，导致识别错误。
由于这些挑战的存在，对遮挡行人重识别问题的研究可以拓宽行人重识别技术的应用场景，应对更复杂的情况，因此具有很高的研究价值和实际意义。

1.2遮挡行人重识别问题研究现状
行人重识别问题最早被称为跨区域目标匹配。在2006年的计算机顶会CVPR上，Gheissari等首次提出了行人重识别（Person Re-identification）的概念，当时是把图像的颜色及边缘直方图作为图像特征进行人物匹配的。传统的人物重识别方法分为图像特征提取和相似性度量两个阶段。随着近年来深度学习的发展及在计算机视觉领域的广泛应用，越来越多的研究学者借助深度学习模型来实现行人重识别任务。2014年，在Yi等人发表的论文中，首次将深度学习应用到行人重识别领域，联合学习了特征提取和相似性度量两个过程，并且取得了较好的成果。本节将分别从手工特征设计和基于深度学习的行人重识别方法介绍国内外研究动态。
1.2.1基于手工特征的行人重识别
在深度学习发展起来以前，行人重识别任务都是基于人工提取特征的方法来做的。常用的特征有颜色、形状、纹理等表层特征。颜色特征是行人图像中最具表现力的特征之一，一些学者提出了基于颜色的特征描述。Farenzena等最早通过图像颜色直方图和颜色空域排序提取特征，同时还利用了空间位置信息来实现行人重识别。但颜色信息易受到光照和遮挡等因素影响，提取到的特征鲁棒性低。Gray等人利用Adaboost算法，将行人图像分成若干水平条纹，在RGB，YCbRC和HS颜色空间中计算颜色直方图，并用具有旋转不变性的Gabor滤波器和Schmid滤波器计算纹理直方图，提取了颜色特征和纹理特征，相比较单独使用颜色特征，提高了重识别的准确率。Sebastian等人将图像划分为一个个三角形区域，提取了局部特征。Zeng等[7]提出融合了空间直方图和协方差的行人特征描述符，空间特征来自身体不同区域的颜色通道，并以颜色和强度梯度作为像素特征。Matsukawa等人提出了一种基于像素层次分布的特征表示方法，将图像分成多个水平区域，再把每个区域细分为多个局部块，并用高斯分布建模局部块的颜色特征和纹理特征，即把各个水平区域建模为一组的多个高斯分布，其中每个高斯分布作为局部区域的特征，最后再用一个高斯分布来描述这组高斯分布的特性，以此得到图像的特征。Liao等人提出了LOMO（Local Maximal Occurrence）特征。首先把图像经过Retinex多尺度变换，可以减少光照变化对图像的影响。然后用一个小窗口在图像上滑动，计算每个窗口的HSV颜色直方图和纹理直方图得到局部特征，并融合所有子窗口在同一水平位置的特征，以此得到全局特征，这样可以减小视角变化带来的影响。由于减小了光照、视角和分辨率的影响，又兼顾了特征提取效率和准确率，该方法超过了同年大部分深度学习方法。
1.2.2基于深度学习的行人重识别
随着深度学习的兴起及卷积神经网络在图像处理领域的强大优势，以及基于传统手工特征的行人重识别方法性能提升遇到瓶颈，很多研究学者转向借助深度模型来解决行人重识别问题，并且随着研究的深入，很多提出的方法性能都优于基于传统手工特征的方法。基于传统手工特征的方法把特征提取和相似性度量分开独立进行，而深度学习模型协同优化特征提取和度量学习两个模块，以端到端的方式训练网络，简化了行人重识别任务，并且提高了识别准确率。
（2）基于局部特征的ReID方法
以前的行人重识别研究中人们大都关注全局特征，就是图像输入之后简单的经过一些卷积层、池化层、全连接层和激活后得到图像的特征向量。随着研究的深入，基于全局特征的重识别任务性能也遇到了瓶颈，慢慢就有研究学者开始关注局部特征。Rahul[12]等人最早将图片沿水平方向切分成若干块，再分别提取每一块的特征，如图所示。这种方法要求输入图像严格对齐，否则会出现一张图像上的头部和另外一张图像上的身体部位进行比对的情况，对模型训练来说这显然是致命的。但不可能所有的输入图像中行人都是对齐的，为了解决这个问题，Zheng[13]等人提出了人体姿态和骨架关键点模型。模型把行人分为14个关键点，再把这14个关键点划分三个区域，把三个区域对齐以矫正图像，然后把矫正后的图像和原始图像作为模型输入，最后输出包含全局和局部信息的特征向量。而在Zhao[14]等人的工作中也用到了关键点模型提取特征，但提出的Spindle Net没有追求局部区域的对齐，而是用关键点信息取出图像的ROI（Region of interest），具体如图，先用关键点模型提取出14个人体关键点，再由关键点得到7个ROI，分别是四肢的四个区域和头、上身、下身。再把ROI和原始图像输入模型提取特征。ROI得到的是7个局部特征，原图像得到的是一个全局特征，这些特征整合之后作为行人重识别任务的特征。为了避免引入额外的人体姿态估计和关键点模型，Zhang[16]等提出了基于距离的自动对齐模型，如图所示，该方法可以将图片中的行人自动对齐，之后把图像切分成若干块，分别提取各自的局部特征。
（3）基于度量学习的ReID方法
表征学习让网络训练特征提取能力，旨在让提取出来的特征更具区分力，而度量学习则是通过网络学习出两张图片的相似度。通过最大化类间距离和最小化类内距离来让模型提高识别能力，具体的，让属于同一个身份的不同图像之间的相似度变大，让属于不同身份的不同图像间的相似度变小，且至少要比同一个身份的不同图像之间的相似度小一个margin。目前提出的度量学习损失函数有对比损失(Contrastive loss) [5]、三元组损失(Triplet loss)[6-8]、 四元组损失(Quadruplet loss)[9]、难样本采样三元组损失(TriHard loss)[10]、边界挖掘损失(MSML)[11]。这些损失函数以欧氏距离或者余弦距离作为度量。孪生网络即是用对比损失训练的。输入的是一个图像对，标签x=1表示这两张图像属于同一个身份，x=0则表示输入的图像属于不同身份。损失函数为。
三元组损失是被用的最多的损失，其输入为三张图像别为Anchor、Positive、Negative。Positive和Anchor属于同一身份，Negative和Anchor属于不同身份。三张图像分为两个图像对，sitive和Anchor（正样本）、Negative和Anchor（负样本），之后输入到网络进行训练。网络会让正样本之间的距离变小，让负样本之间的距离变大，最后让模型可以更好的完成行人重识别任务。四元组损失是基于三元组损失提出来的，相比于三元组损失，四元组损失要求输入两张负样本图像，两个负样本属于不同身份。三元组损失只考虑正负样本间的相对距离，而四元组通过设定一大一小的margin，让网络能考虑到正负样本间的绝对距离，这样模型能学到更好的特征。难样本采样三元组损失是Alexander[10]等人提出的另一种改进的三元组损失，相比于传统的三元组损失，难样本采样方法并不是直接随机从数据集中选取Positive和Negative，而是从输入的一个batch中挑选出一张与Anchor最不相似的但属于同一身份的图像作为Positive，再选出一张与Anchor最相似的但不属于同一身份的图像作为Negative。这么做的出发点是属于同一身份的图像之间的相似度原本就比属于不同身份的图像间的相似度高，所以训练出来的网络泛化能力低，而难样本采样三元组损失训练出来的网络无疑具有更强的泛化能力。
1.2.3遮挡行人重识别
大多数研究学者都假设能拍到行人完整的图像，实际上这是一种较为理想的情况，现实场景中会遇到各种遮挡问题，而目前提出的行人重识别方法在测试带有遮挡的数据集时性能急剧下降，这也是为什么现在行人重识别还只是停留在研究阶段，很难落地的原因。随着在行人重识别领域研究的深入，开始有学者关注遮挡问题。Zhang等人提出了模糊匹配模型，为了应对遮挡问题，模型把输入图像分为若干图像块，并引入了图像块相似性评分机制，还利用了空间布局信息来让图像块尽可能对齐匹配。Kin等人研究的是部分行人图像，可以看成一种特殊的遮挡。他们的模型把人体划分为13个局部区域，对于具体的图像，在遮挡情况下，这13个局部区域会丢失其中一部分，匹配的时候仅针对两图像中共有的区域。He提出了另一种针对部分人重识别的方法，该方法分为FCN和DSR两部分。常规的行人重识别任务中，输入图像大小是相同的，而在部分行人重识别中图像大小不一，作者就在FCN部分删除了全连接层，只保留了卷积层和池化层，因为全连接层最后需要输出固定大小的特征向量。这样FCN就能根据输入图像的大小，输出大小可变的特征图。DSR部分通过重构特征来训练网络，具体地由FCN得到两张输入图像的特征向量X和Y，作者用Y中项的线性组合来重构X，重构矩阵w为一个稀疏矩阵，因为Y中只有很少一部分与重构X相关。通过最小化重构之后的同ID特征向量之间的距离，最大化不同ID特征向量之间的距离来训练模型。Miao等人提出了一种姿势引导特征对齐(Pose-Guided Feature Alignment，PGFA)的方法来解决行人重识别中的遮挡问题。该研究中作者重构了数据集，把原数据集中query部分遮挡图像占比由15%提升到了100%。为了提取关键点，作者通过COCO数据集标注的人体特征点数据训练一个人体特征点检测网络，利用姿态将有用信息从遮挡中分离出来。将遮挡图像输入网络，得到了未遮挡区域的关键点，并利用关键点坐标来生成注意力图，生成的注意力图指示了特定的身体部位是否遮挡，引导模型关注没有遮挡的区域，在匹配时，模型只会计算两张图像中没有遮挡区域的相似度。Zhuo等人提出了人体注意力框架(AFPB)以解决遮挡问题。该框架包括两部分，遮挡模拟器（Occlusion Simulator，OS）和多任务损失网络。OS是为了应对遮挡数据集不足的问题，在无遮挡的图像上随机生成遮挡块，增加了网络的训练数据。在多任务损失模块融合了识别损失和遮挡/非遮挡二分类损失，迫使网络不仅要区分行人身份，还要识别出一个样本是有遮挡的还是无遮挡的。实验结果表明该模型在遮挡行人重识别任务上的有效性。以上介绍了一些目前提出的针对遮挡行人重识别比较有效的方法，大部分都是先取出未遮挡的区域，然后针对未遮挡的区域提取特征，各方法的不同点在于如何更好的提取未遮挡区域的特征，使得到的特征更具鲁棒性和鉴别力。 
1.3本文主要内容
本文主要针对遮挡场景下的行人重识别问题，介绍一个针对公开数据集目前表现最好的方法，并在此基础上做了一些改进，并通过实验证明了改进是有效果的。
该方法主要包括三个模块，分别是一阶语义模块（Semantic，S）、高阶关系模块（Relation，R）和高阶人体拓扑模块（Human-Topology，T）。
r(k)={█(1   如果前n项包含和query相同身份的图像@0 其他)┤

1.4本文的组织结构
2相关背景知识介绍
2.1深度学习相关理论
2.1.1卷积神经网络
2.1.2ResNet50
2.2图卷积
2.3遮挡行人重识别评价指标
2.3.1 rank-1
2.3.2 map
2.4遮挡行人重识别数据集
2.5本章小结
3遮挡行人重识别研究
3.1问题描述与框架设计
3.2一阶语义
3.3高阶关系
3.4高阶人体拓扑结构
3.5本章小结
4实验
4.1xx

5总结与展望
5.1总结
5.2展望
